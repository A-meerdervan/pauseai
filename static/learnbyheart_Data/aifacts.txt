subset;Fun and important AI facts

How many “parameters” does the human brain have?;1000 trillion;” On average, the human brain contains about 100 billion neurons [...]. Each neuron may be connected to up to 10,000 other neurons, passing signals to each other via as many as 1,000 trillion synapses. In the nervous system, a synapse is a structure that permits a neuron to pass an electrical or chemical signal to another neuron or to the target effector cell.” This was taken from <a href="https://arxiv.org/abs/1906.01703#:~:text=On%20average%2C%20the%20human%20brain,many%20as%201%2C000%20trillion%20synapses">this paper</a>. In deep learning, we talk about how many parameters an AI model has. The brain is not an exact analogy to AI models, but the parameters are mainly the weights of the connections between artificial neurons. You could understand this as the connection strength. Conceptually, for example, the neuron that detects a car has a strong connection to the neuron that detects a wheel. GPT-4 has 1.8 trillion parameters, which is 0.2% of the “parameter” count of the human brain. Which is really, really close, only 500 times increase and the counts are equal. Note that we do not know the minimal parameter count for a superintelligence, it could be lower than the number of synapses in the brain.

How many billion parameters does GPT-4 consist of? (GPT-3 consists of 175 billion parameters);1800;GPT-4 is the big brother of GPT-3, and it is scary good, so good that it triggered fear and action in PauseAI activists. In July 2023 the free version of Chat-GPT is powered by GPT-3.5 while GPT-4 powers the paid version of Chat-GPT. 1800 billion or 1.8 trillion is the parameter count. OpenAI chose to keep the details of the size and training of GPT-4 a secret. But the details were leaked, (<a href="https://medium.com/@daniellefranca96/gpt4-all-details-leaked-48fa20f9a4a">read all about it here</a>). The main info: trained for 90-100 days, using around 25,000 Nvidia A100 GPUs rented in the Microsoft Azure suite, uses mixture of experts, so not one big model but 16, ~110 billion parameter models that deal with different domains, the training cost was estimated to be 63 million dollars, but CEO Sam Altman has been asked about the cost being more than 100 million dollars, and he said that it cost more than that. What are parameters? The parameters are mainly the weights of the connections between artificial neurons. You could understand this as the connection strength. Conceptually, for example, the neuron that detects a car has a strong connection to the neuron that detects a wheel.

During the summer of what year was the field of AI research founded?;1956;The field of AI research was founded at a workshop held on the campus of Dartmouth College, USA during the summer of 1956. In 1955 in the proposal for this workshop, the term artificial intelligence was first coined by John McCarthy. Those who attended would become the leaders of AI research for decades. Names include Marvin Minsky, Claude Shannon, John McCarthy and Warren McCulloch. Many of them predicted that a machine as intelligent as a human being would exist in no more than a generation, and they were given millions of dollars to make this vision come true. <a href="https://en.wikipedia.org/wiki/History_of_artificial_intelligence">Source: Wikipedia history of AI</a> and <a href="https://en.wikipedia.org/wiki/Dartmouth_workshop"> Wiki Dartmouth workshop</a>. 

In what year did Alan Turing publish the description of the Turing Test?;1950;Alan Turing is one of the fathers of the computer, an Einstein level individual who worked on computers and cracking german war codes. The Turing test, originally called the imitation game by Turing, is a test of a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. Turing proposed that a human evaluator would judge natural language conversations between a human and a machine designed to generate human-like responses. The evaluator would be aware that one of the two partners in conversation was a machine, and all participants would be separated from one another. The conversation would be limited to a text-only channel, such as a computer keyboard and screen, so the result would not depend on the machine's ability to render words as speech. If the evaluator could not reliably tell the machine from the human, the machine would be said to have passed the test. The test results would not depend on the machine's ability to give correct answers to questions, only on how closely its answers resembled those a human would give. <a href="https://en.wikipedia.org/wiki/Turing_test">Source: Wikipedia</a>. It is amazing that Turing was already thinking about how to test for human level intelligence in computers when the computers in his time were ridiculously slow and expensive. He already believed we would succeed in making them billions of times faster and cheaper! What a visionary. Note that he wrote about this in 1950, 6 years before the AI research field was officially founded!

In AI, there is a group of approaches that deal with an agent that takes actions in an environment and learns from trial and error. This group of approaches is often abbreviated to two letters, enter them.;RL;RL stands for Reinforcement Learning. Examples of popular successes of RL: AlphaGo beating the Go world champion, DeepMind playing Atari games at superhuman level, controlling robots to grasp unseen objects and more. RL is awesome because it makes it possible for the agent to become superhuman, and it does not need a dataset created by humans, the data is experience which can be obtained crazy fast in a simulated environment or more slowly in reality. Watch <a href="https://www.youtube.com/watch?v=JgvyzIkgxF0">this video</a> to learn more. 

How many hours of playing itself, did it take AlphaZero to arguably learn more about the board game Go, than humanity has learned in more than 3000 years?;30;Go is often called the Chinese form of chess, but it is much more complex than chess because it has more possible board states than there are atoms in the universe. In 2016, DeepMind's AlphaGo defeated world champion Lee Sedol after having been partly trained on millions of human Go matches. In 2017, they came out with AlphaGo Zero that beat the 2016 version of AlphaGo that beat Lee Sedol, after 3 days of training using zero human match data! Later in 2017, they built a more general system, AlphaZero, that became the strongest player in history for Go, Chess and Shogi (often called Japanese chess). For Go, it reached the same level in only 30 hours! The zero in AlphaZero stands for zero human knowledge or data used during training. It simply learns by playing games against itself, starting from completely random play. Why do we say “learned more than humanity in 3000 years?”, because since the beginning of Go play, the best strategies are taught to Go students growing the cumulative amount of knowledge. We encourage you to watch <a href ="https://www.youtube.com/watch?v=7L2sUGcOgh0&t=190s">this 4 minute DeepMind video</a> about it. To many, this is a warning sign of just how quickly AGI could learn complex new skills. 

What is the name of the computer program that first defeated a world chess champion, Garry Kasparov?;Deep Blue;This was a media spectacle with headlines like “The brain’s last stand”. Two times, first in 1996 where humanity won, then in 1997 IBM's Deep Blue beat Kasparov in a series of matches. Deep Blue made much use of human chess strategic knowledge that was put in the program. Unlike AlphaZero, that learned to become the best chess program from scratch. <a href="https://medium.com/@matthewlibby_75648/the-brain-across-the-table-garry-kasparov-vs-deep-blue-1997-7904f77cebf7">Here a medium post about the matches with Kasparov</a>. 

How many hours of playing itself, did it take AlphaZero to arguably learn more about chess, than humanity has learned collectively in the last 1500 years?;4;The 2017 DeepMind program AlphaZero became the strongest player in history for chess, shogi (often called Japanese chess) and Go (often called Chinese chess). Chess is said to originate from India from over 1500 years ago. In chess, AlphaZero first outperformed the then best superhuman computer program called Stockfish after just 4 hours of training, by only playing games against itself! This shows AI can be scary fast and superhuman. We encourage you to watch <a href=”https://www.youtube.com/watch?v=7L2sUGcOgh0&ab_channel=GoogleDeepMind">this 4-minute YouTube video about it from DeepMind</a>. To many, this shows that the argument that AI learns from human data and therefore can not see past or be smarter than humans, is nonsense. The 4 hours was taken from <a href = "https://www.deepmind.com/blog/alphazero-shedding-new-light-on-chess-shogi-and-go">this DeepMind blog post</a>. 

How long did it take the first autonomous vehicle (a small cart at Stanford) to navigate through a room with chairs as obstacles?;5 hours;One can disagree on what counts as an autonomous vehicle and which was first. But this cart was able to use computer vision to understand camera images, and it moved in one meter spurts, punctuated by ten to fifteen minute pauses for image processing and route planning. This achievement to cross the chair-filled room without human intervention happened in 1979. Work done by Hans Moravec. More on <a href="https://web.stanford.edu/~learnest/sail/oldcart.html">this page by Stanford</a>.

What is the last name of the AI professor that quit his job at Google to be able to speak freely about the existential risk posed by AI?;Hinton;Geoffrey Hinton is considered an AI pioneer who believed in the now dominant methods of deep learning, multi layered neural networks, when little others did, and contributed much to the field. Even often called “the godfather of AI”. In 1986, he improved the backpropagation algorithm that is central to deep learning. And he has received the 2018 Turing Award together with Yann LeCun and Yoshua Bengio, often considered the Nobel Prize in computer science. We thank Hinton for speaking out about the dangers and making a huge media splash. It is interesting however to note that he quit his Google job at age 75, so he was already soon to retire. Read more about his statements <a href = "https://www.bbc.com/news/world-us-canada-65452940">here in a piece by the BBC</a>.

What is the last name of the first head of state to take AI existential risk seriously and take action?;Sunak;In 2023 the prime minister of the UK, Rishi Sunak, met with DeepMind, OpenAI and Anthropic CEO’s. Taken from <a href="https://www.theguardian.com/technology/2023/may/25/no-10-acknowledges-existential-risk-ai-first-time-rishi-sunak">this Guardian piece</a>: “The PM and CEOs discussed the risks of the technology, ranging from disinformation and national security, to existential threats […] The PM set out how the approach to AI regulation will need to keep pace with the fast-moving advances in this technology”. The UK is organizing a summit on AI safety in 2023 and has started the Foundation model taskforce, that has gotten a 100 million pound budget to increase AI safety, led by Ian Hogarth, the author of the influential and recommended Financial Times piece titled: <a href="https://www.ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2">We must slow down the race to god-like AI</a>. Sadly, Sunak talks of acceleration, not slow-down. 

subset;Learn key figures through quotes

Quote by whom?: Can we just stop rushing ahead long into what seems like through very basic reasoning to be probably an apocalypse?;Miles;July 2023, Robert Miles, legendary AI safety YouTuber with more than 140k subscribers, said this on the Futurati podcast <a href = "https://youtu.be/r-SmqbqIiXk?t=4888">found here on YouTube</a>. Find his videos on this website on <a href="/learn">the learn page</a>. 

Quote by whom?: Mark my words, AI is far more dangerous than nukes;Musk;March 2018, Elon Musk said this, <a href="https://www.cnbc.com/2018/03/13/elon-musk-at-sxsw-a-i-is-more-dangerous-than-nuclear-weapons.html">Source CNBC</a>.

Quote by whom?: I thought AlphaGo was based on probability calculation and that it was merely a machine. But when I saw this move, I changed my mind. Surely, AlphaGo is creative;Sedol;This was said by then 18 time world champion in Go, Lee Sedol after having lost to DeepMind's AlphaGo system in 2016. Go is often called the Chinese form of chess, but it is much more complex than chess because it has more possible board states than there are atoms in the universe. The move he refers to is the now famous "move 37". AlphaGo's 4-1 victory in Seoul, South Korea, on March 2016 was watched by over 200 million people worldwide. This landmark achievement was a decade ahead of its time. Read more about it <a href="https://www.deepmind.com/research/highlighted-research/alphago">on the DeepMind blog</a>, there they also link a free 1,5 hour long documentary about everything around this historic event. 

Quote by whom?: I'm Afraid I Can't Do That, Dave;HAL 9000;This is an historic line from the rogue computer program, HAL 9000 in the 1968 science fiction movie "2001: A Space Odyssey". You can watch the relevant <a href="https://www.youtube.com/watch?v=Mme2Aya_6Bc">1-minute video bit here on YouTube</a>.

Quote by whom?: If we pursue [our current approach], then we will eventually lose control over the machines;Russell;Said by AI professor Stuart Russell, author of the #1 textbook on Artificial Intelligence used in most AI university programs. Russell is an AI safety researcher and has been very public about his concerns about the existential risk of AI. He is also a key figure in the discussion about autonomous weapons and much more. <a href="https://news.berkeley.edu/2023/04/07/stuart-russell-calls-for-new-approach-for-ai-a-civilization-ending-technology/">Quote taken from here</a>. On the /learn page on this website we link to <a href="https://www.youtube.com/watch?v=ISkAkiAkK7A&ab_channel=CITRIS">this talk by Stuart Russell</a> where you can learn his views on our situation.

Quote by whom?: […] rogue AI may be dangerous for the whole of humanity […] banning powerful AI systems (say beyond the abilities of GPT-4) that are given autonomy and agency would be a good start;Bengio;AI professor Yosua Bengio said this in 2023 in his blog post titled <a href="https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/">How rogue AI’s may arise</a>. We recommend reading this powerful post. Bengio is a deep learning pioneer and winner of the Turing Award. He is one of the most prominent figures that has signed the influential <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open letter calling for a pause</a> in early 2023. We also recommend watching <a href="https://www.youtube.com/watch?v=144uOfr4SYA">the Munk Debate</a> on whether AI is or is not an existential risk, with Bengio, Tegmark, LeCun and Mitchell.

Quote by whom?: The development of full artificial intelligence could spell the end of the human race;Hawking;Stephen Hawking <a href="https://nypost.com/2023/05/01/stephen-hawking-warned-ai-could-mean-the-end-of-the-human-race/">said this in 2014 to the BBC</a>. Now passed away, he was a famous theoretical physicist, cosmologist and author.

Quote by whom?: I wouldn't like to devalue climate change. I wouldn't like to say, you shouldn't worry about climate change. That's a huge risk too, but I think this might end up being more urgent. With climate change, it's very easy to recommend what you should do: you just stop burning carbon. If you do that, eventually things will be okay. For this, it's not at all clear what you should do;Hinton;AI professor Geoffrey Hinton is considered an AI pioneer who believed in the now dominant methods of deep learning, multi layered neural networks, when little others did, and contributed much to the field. Even often called “the godfather of AI”. In 1986, he improved the backpropagation algorithm that is central to deep learning. And he has received the 2018 Turing Award together with Yann LeCun and Yoshua Bengio, often considered the Nobel Prize in computer science. We thank Hinton for speaking out about the dangers and making a huge media splash. It is interesting, however, to note that he quit his Google job at age 75, so he was already soon to retire. <a href="https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/">Source of this quote from May 2023</a>. 

Quote by Whom?: Shut down all the large GPU clusters [...]  If intelligence says that a country outside the agreement is building a GPU cluster, be less scared of a shooting conflict between nations than of the moratorium being violated. Be willing to destroy a rogue datacenter by airstrike. [...] We are not ready. We are not on track to be significantly readier in the foreseeable future. If we go ahead on this, everyone will die, including children who did not choose this and did not do anything wrong;Yudkowsky;Eliezer Yudkowsky was one of the first people to work full time on AI safety and has written about this topic extensively. He founded AI safety research organization MIRI, and AI safety YouTuber Robert Miles has said Yudkowsky was a great inspiration to him. In early 2023 FLI published <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">the open letter that calls for a pause</a> on developing models more powerful than GPT-4. This quote is taken from Yudkowsky’s response to that letter that was published in TIME magazine. This piece by Yudkowsky has become controversial due to its call to governments to use military force against countries that ignore proposed international agreements and because of the dramatic, emotional language. Whether you agree or disagree, we strongly recommend reading both the FLI letter and <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/">the Yudkowsky TIME piece</a>, both are important pieces of world history. 

Quote by Whom?: Development of superhuman machine intelligence is probably the greatest threat to the continued existence of humanity;Altman;The CEO of OpenAI (behind GPT-4 and ChatGPT) Sam Altman said this in <a href="https://blog.samaltman.com/machine-intelligence-part-1">his 2015 blog post</a>. We say, if you believe this, then stop rushing towards the cliff!

Quote by Whom?: AI could decide that humans are a threat;Gates;Bill Gates (co-founder of Microsoft, which owns 50% of OpenAI (company behind Chat-GPT)). <a href="https://www.denisonforum.org/daily-article/bill-gates-ai-humans-threat/">Source</a>.

Quote by Whom?: I’ve not met anyone in AI labs who says the risk [from training a next-gen model] is less than 1% of blowing up the planet. It’s important that people know lives are being risked;Tallinn;Said by Jaan Tallinn, the lead investor of Anthropic. His Wikipedia starts with: Jaan Tallinn is an Estonian billionaire computer programmer and investor known for his participation in the development of Skype and file-sharing application FastTrack/Kazaa. Jaan Tallinn is a leading figure in the field of existential risk, having co-founded both the Centre for the Study of Existential Risk (CSER) at the University of Cambridge, in the United Kingdom and the Future of Life Institute in Cambridge, Massachusetts, in the United States. Tallinn was an early investor and board member at DeepMind (later acquired by Google) and various other artificial intelligence companies.<a href="https://twitter.com/liron/status/1656929936639430657">Source of the quote</a>.

Quote by Whom?: Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war;Everyone;This is the one sentence open letter that was signed by a large portion of the biggest names in AI in May 2023, so the answer here is jokingly, everyone. It made a big media splash. The CEO’s of DeepMind, OpenAI and Anthropic signed it. Many people have been stating that they think it is not sincere, that the industry people are just creating hype for how important and powerful their creations are becoming. But please note that the vast majority of the big AI names that signed it are academic researchers that would not have this supposed incentive. PauseAI founder Joep Meindertsma has written <a href="https://twitter.com/PauseAI/status/1671061114786832384">this tweet about this topic</a>. 

Quote by whom?: From AI's perspective in 2-3 years from now, we look more like plants than animals: big slow chunks of biofuel showing weak signs of intelligence when undisturbed for ages (seconds) on end. [...] Over the next decade, expect AI with more like a 100x - 1,000,000x speed advantage over us;Critch;Said in <a href="https://twitter.com/AndrewCritchCA/status/1680461874171658242">a tweet worth reading here by Andrew Critch</a> in July 2023. Critch is an AI researcher at UC Berkeley and the CEO of Encultured AI. But to believe this point, just use ChatGPT and see how much faster it is than you in answering a difficult question combined with the steady advances in computing and improvements in algorithms. Please consider taking 1 minute to <a href="https://vimeo.com/83663312">watch this short video</a> that shows how humans look from the perspective of an observer that runs 50 times faster. It works well to get a sense of just how plant-like we would look.  

Quote by whom?: Why didn't I think about it before? Why didn't Geoffrey Hinton think about it before? [...] I believe there's a psychological effect that still may be at play for a lot of people. [...] It's very hard, in terms of your ego and feeling good about what you do, to accept the idea that the thing you've been working on for decades might be actually be very dangerous to humanity. [...] I think that I didn't want to think too much about it, and that's probably the case for others;Bengio;AI professor Yoshua Bengio said this in a July 2023 <a href="https://www.youtube.com/watch?v=0RknkWgd6Ck&t=961s&ab_channel=EyeonAI">YouTube interview found here</a>. Bengio is a deep learning pioneer and winner of the Turing Award. He is one of the most prominent figures that has signed the influential <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open letter calling for a pause</a> in early 2023. We also recommend watching <a href="https://www.youtube.com/watch?v=144uOfr4SYA">the Munk Debate</a> on whether AI is or is not an existential risk, with Bengio, Tegmark, LeCun and Mitchell. If you want to read more about the psychology of existential risk consider reading <a href="https://pauseai.info/psychology-of-x-risk">this piece written by PauseAI founder Joep Meindertsma</a>.

Quote by whom?: If we are not careful, we might be trapped behind a curtain of illusions, which we could not tear away, or even realize is there;Harari;History professor and best-selling author Yuval Noah Harari (known from the book Sapiens) said this in April 2023.  Harari “argues that AI has hacked the operating system of human civilization. Storytelling computers will change the course of human history, says the historian and philosopher”. <a href="https://www.economist.com/by-invitation/2023/04/28/yuval-noah-harari-argues-that-ai-has-hacked-the-operating-system-of-human-civilisation">Paywalled source here</a>. Harari signed the <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">FLI open letter calling for a pause</a> of AI development of models more powerful than GPT-4, and has been doing a lot of public talks on the risks of AI in the first half of 2023. 