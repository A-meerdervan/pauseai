---
title: PauseAI Proposal
description: We want our governments to organize a summit to pause the development of AI systems more powerful than GPT-4.
---

**Implement a temporary pause on the development of AI systems more powerful than GPT-4**.

This moratorium needs to be implemented on an international level because we cannot expect countries or companies to risk their competitive advantage by pausing AI development on their own.

An international agreement is typically established through a summit, where leaders of countries meet to discuss the issue and make a decision.

We need our leaders to understand the urgency of the situation, and to take action **right now**:

- A country needs to step up and **host a [summit](/summit)**. Pick a date and a location, then invite all UN member states.
- A **treaty** needs to be created. This treaty should specify what types of AI development are illegal, and which consequences there are to not abiding. This treaty needs to be signed by all UN member states.

## Suggested contents of the treaty

- Ban the development of AI systems more powerful than GPT-4, until the alignment problem is solved.
- Set up an international AI safety agency, similar to the IAEA. This agency will be responsible for:
  - Periodic meetings to discuss the progress of AI safety research.
  - Granting approval to conduct any new training run above a certain size (e.g. 1 billion parameters).
- Increase national investments in AI safety research. Right now, there exist only a few hundred AI safety researchers. This should become thousands.
- Hold AI companies accountable for criminal acts committed using their AI systems.
- Ban training of AI systems on copyrighted material.
- Track the sales of GPUs and other hardware that can be used for AI training.
