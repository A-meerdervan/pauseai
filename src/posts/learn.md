---
title: Learn about AI alignment
description: Educational resources (videos, articles, books) about AI alignment
---

One of the most important things you can do to help with AI alignment and the existential risk that is poses, is to learn about it.
Here are some resources to get you started.

## Videos

- [How to get Empowered, not overpowered by AI](https://www.youtube.com/watch?v=2LRwvU6gEbA) (15 mins). A brief introduction to the importance of getting AI alignment right.
- [Robert Miles' YouTube videos](https://www.youtube.com/watch?v=nKJlF-olKmglist=PLqL14ZxTTA4fyhYg6xD6Fz05WcuxLGseL) are a great place to start understanding most of the fundamentals of AI alignment. If you want to really learn how AI aligment works, start here!
- [Max Tegmark with Lex interview](https://youtu.be/VcVfceTsD0A?t=1547) (2 hrs). Interview that dives into the details of our current dangerous situation. _"It's like 'Don't look up', but we are building the asteroid ourselves."_
- [The AI Dilemma](https://www.youtube.com/watch?v=xoVJKj8lcNQ&t=1903s) (1hr). Presentation about the dangers of AI and the race which AI companies are stuck in.

## Websites

- [AISafety.net](https://aisafety.info/) is an absolutely amazing database of questions and answers.

## Podcasts
- [AI X-Risk Research podcast](https://axrp.net/). In-depth interviews with experts in the field of AI alignment.
- [Future of Life podcast](https://soundcloud.com/futureoflife)

## Courses

- [AGI safety fundamentals](https://www.agisafetyfundamentals.com/) (30hrs)

## Organisations

- [Future of Life Institute](https://futureoflife.org/cause-area/artificial-intelligence/) started the [open letter](https://futureoflife.org/open-letter/pause-giant-ai-experiments/)
- [Effective Altruism](https://www.effectivealtruism.org/). A community of people, many of which are highly concerned about AI safety. They also have a great [post on pursuing a career](https://forum.effectivealtruism.org/posts/7WXPkpqKGKewAymJf/how-to-pursue-a-career-in-technical-ai-alignment) in AI alignment.
